#
# Example: deploy a Spark/YARN cluster on Ubuntu 14.04 VMs
#
# This example covers the installation of a Hadoop cluster with Spark, Hive, and
# JupyterHub (with PySpark kernel support). The cluster consist of 1
# front-end/master node (which runs Hadoop YARN ResourceManager and HDFS
# NameNode services) plus 8 slave nodes (which run Hadoop YARN slaves and HDFS
# DataNodes). The master node also runs JupyterHub (access it on port 443), NFS
# server for home directories, and NIS/YP server for accounts (use in
# JupyterHub). The configuration is *incomplete* and needs to be complemented
# with a suitable `cloud` section.
#
# For more details about the configuration, see:
# - http://elasticluster.readthedocs.io/en/latest/configure.html
# - http://elasticluster.readthedocs.io/en/latest/playbooks.html#id4
#

[setup/hadoop+spark]
provider=ansible
master_groups=hadoop_master,jupyterhub,ansible
worker_groups=hadoop_worker

# install NIS/YP to manage cluster users
global_var_multiuser_cluster=yes


# the `login` section collects information about how to log-in to VMs, including
# SSH key to use for connections
[login/ubuntu]
image_user=ubuntu
image_user_sudo=root
image_sudo=True
# name of SSH key the cloud controller will inject into VMs
user_key_name=elasticluster
# these should match the SSH key named above
user_key_private=~/.ssh/id_rsa
user_key_public=~/.ssh/id_rsa.pub


[cluster/hadoop-on-ubuntu14]
setup=hadoop+spark
master_nodes=1
# adjust size to taste
worker_nodes=8
ssh_to=master

# this is cloud-specific info (using OpenStack for the example)
cloud=openstack
flavor=1cpu-4ram-hpc
network_ids=c86b320c-9542-4032-a951-c8a068894cc2
security_group=default

# Ubuntu 14.04 (cloud-specific ID)
image_id=42cd892c-cd5f-401d-963a-14ec1040ed51

# `login` info is -in theory- image-specific
login=ubuntu
