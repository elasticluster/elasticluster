#
# ElastiCluster example: SLURM cluster with GPUs on Amazon EC2
#
# This is a complete and self-contained example that should get you
# started with running SLURM clusters with GPU-accelerated compute
# nodes on AWS EC2.  Note that, as of Jan. 2018, GPU-enabled VMs are
# available only in few zones so you may not be able to run this
# example in your default region/zone.
#
# For more details, see:
# - http://elasticluster.readthedocs.io/en/latest/configure.html
# - http://elasticluster.readthedocs.io/en/latest/playbooks.html#id5
#


# SLURM software to be configured by Ansible
#
# (There is nothing AWS-specific in the "setup" section; in fact, it can be
# re-used verbatim with *any* cloud provider or base image)
[setup/slurm]
provider=ansible
frontend_groups=slurm_master
# the `cuda` role installs support for NVIDIA GPUs and the CUDA
# runtime and development toolkit
compute_groups=slurm_worker,cuda

# if the NVIDIA drivers are not installed correctly, you might need to
# ElastiCluster to reboot the nodes -- this is accomplished by the
# following variable setting. (ATM, needed on CentOS/RHEL but not on Ubuntu.)
compute_var_allow_reboot=yes

# If nodes have multiple GPUs, you want to enable cgroup support in
# SLURM to be sure that a job can access only the GPUs that were
# allocated to it.
global_var_slurm_taskplugin=task/cgroup
global_var_slurm_proctracktype=proctrack/cgroup


[cloud/amazon-eu-west-1]
provider=ec2_boto
ec2_url=https://ec2.eu-west-1.amazonaws.com
ec2_access_key=*** LOOK THIS UP IN THE WEB-BASED CONSOLE ***
ec2_secret_key=*** LOOK THIS UP IN THE WEB-BASED CONSOLE ***
# note: AMIs differ from one region to the other -- if you change the region here,
# you might need to change the `image_id` setting in the cluster section below
ec2_region=eu-west-1


# the `login` section collects information about how to log-in to VMs, including
# SSH key to use for connections
[login/centos]
image_user=centos
image_user_sudo=root
image_sudo=True
user_key_name=elasticluster
user_key_private=~/.ssh/id_rsa
user_key_public=~/.ssh/id_rsa.pub


# Bring all of the elements together to define a cluster called "slurm-gpu"
[cluster/slurm-gpu]
setup=slurm

cloud=amazon-eu-west-1
# check that this security group allows unrestricted
# traffic among cluster nodes!
security_group=default

# CentOS 7 for AWS region eu-west-1
image_id=ami-0d063c6b
login=centos

# On AWS, the presence and number of NVIDIA GPU accelerators depends
# on the machine type.  At the moment of this writing, only P2 and P3
# instances provide CUDA-capable GPUs.
flavor=p2.xlarge

# adjust size of cluster to taste
frontend_nodes=1
compute_nodes=4


[cluster/slurm-gpu/frontend]
# no need for GPUs on the login node
flavor=t2.medium
