# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

# this is local to the master node, so use its memory and vcpu values for computing
spark.driver.memory              {{ ((ansible_memory_mb.nocache.free * 0.875) / ansible_processor_vcpus)|int }}m

# This value depends more on the intended usage of the cluster than on its
# features; still, ElastiCluster has to provide a default. Ideally one woulda use
# the *minimum* RAM-per-core ratio (as that would give the largest compatibility)
# but Ansible and Jinja currently lack filters to allow us to compute the RAM/core
# quotient across all nodes. So use the (max memory) / (average nr. of cores) as a
# "reasonable" approximation...
spark.executor.memory            {{ ((ansible_memory_mb.nocache.free * 0.875) / ansible_processor_vcpus)|int }}m

# Limit of total size of serialized results of all partitions for each Spark action (e.g. collect)
spark.driver.maxResultSize       {{(ansible_memory_mb.nocache.free * 0.8)|int}}m

# Amount of memory to use per python worker process during
# aggregation, in the same format as JVM memory strings (e.g. 512m, 2g).
# If the memory used during aggregation goes above this amount, it will
# spill the data into disks. 
#
spark.python.worker.memory       {{((ansible_memory_mb.nocache.free * 0.875) * 0.5)|int}}m

spark.driver.extraClassPath      /usr/lib/alluxio/core/client/runtime/target/alluxio-core-client-runtime-{{mesos_alluxio_version}}-jar-with-dependencies.jar
spark.executor.extraClassPath    /usr/lib/alluxio/core/client/runtime/target/alluxio-core-client-runtime-{{mesos_alluxio_version}}-jar-with-dependencies.jar

# Maximum amount of time to wait for resources to register before scheduling begins
spark.scheduler.maxRegisteredResourcesWaitingTime 5s

# The minimum ratio of registered resources (registered resources /
# total expected resources) (resources are executors in yarn mode, CPU
# cores in standalone mode) to wait for before scheduling begins.
# Specified as a double between 0.0 and 1.0. Regardless of whether the
# minimum ratio of resources has been reached, the maximum amount of
# time it will wait before scheduling begins is controlled by config
# spark.scheduler.maxRegisteredResourcesWaitingTime. 
#
spark.scheduler.minRegisteredResourcesRatio 0.5

spark.mesos.executor.home           /usr/lib/spark
spark.shuffle.service.enabled       true