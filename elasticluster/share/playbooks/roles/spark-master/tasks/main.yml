# spark-master/tasks/main.yml
---

- name: Parse `spark_history_storage_uri`
  tags:
    - hadoop
    - spark
    - master
  set_fact:
    _spark_history_storage_schema: "{{spark_history_storage_uri.split(':')[0]}}"
    _spark_history_storage_location: "{{spark_history_storage_uri.split(':')[1]}}"


- name: Ensure Spark history storage directory exists on the local filesystem
  tags:
    - hadoop
    - spark
    - master
  file:
    name='{{_spark_history_storage_location}}'
    state=directory
    owner=spark
    group=spark
    mode=0755
  when: '"{{_spark_history_storage_schema}}" == "file"'


- name: Ensure Spark history storage directory exists in HDFS
  tags:
    - hadoop
    - spark
    - master
  command: |
    hdfs dfs -mkdir {{_spark_history_storage_location}}
  when: '"{{_spark_history_storage_schema}}" == "hdfs"'


- name: Deploy Spark environment configuration
  tags:
    - hadoop
    - spark
    - master
  template:
    src='spark-env.sh.j2'
    dest='/etc/spark/conf.elasticluster/spark-env.sh'
    mode=0444


- name: Install Spark packages (master)
  tags:
    - hadoop
    - spark
    - master
  package:
    name: '{{item}}'
    state: '{{ pkg_install_state }}'
  with_items:
    - spark-history-server # History server for Apache Spark
    - spark-master # Server for Spark master


- name: Start Spark master services
  tags:
    - hadoop
    - spark
    - master
  service:
    name="{{item}}"
    state=started
    enabled=yes
  with_items:
    - spark-master
